# M√≥dulos y dependencias de Python (Necesitar√°n instalaci√≥n local: pip install wordcloud matplotlib)
import collections
import string
# Importamos la clase WordCloud directamente para generar la nube.
from wordcloud import WordCloud
# Importamos Matplotlib para mostrar la imagen generada (solo necesario para plt.show() localmente).
import matplotlib.pyplot as plt
# M√≥dulo para el sistema operativo
import os
from typing import Optional, List, Dict, Any

# --- CONSTANTES ---


# Lista de palabras comunes que no aportan valor significativo (stopwords) en espa√±ol.
STOPWORDS_ESPANOL = {
    "el", "la", "los", "las", "un", "una", "unos", "unas", "y", "o", "u", "de", "en", "que", "a",
    "al", "del", "es", "son", "se", "por", "para", "con", "como", "mas", "m√°s", "mi", "me", "te",
    "tu", "su", "sus", "no", "si", "lo", "le", "les", "ha", "han", "he", "est√°", "est√°n", "este",
    "esta", "esto", "pero", "adem√°s", "sin", "tambi√©n", "yo", "nos", "vos", "ello", "ese", "esa", "aquel", "aquella",
    "ser", "estar", "tener", "hacer", "poder", "ir", "haber"
}


# Lee el contenido de un archivo de texto de forma segura manejando errores, ruta_archivo: La ruta completa del archivo a leer, :return: El contenido del archivo como una cadena, o None si hay error.
def leer_archivo(ruta_archivo: str) -> Optional[str]:
    try:
        # Usamos 'with open' para asegurar que el archivo se cierre autom√°ticamente. es crucial especificar la codificaci√≥n 'utf-8' para manejar tildes y caracteres especiales.
        with open(ruta_archivo, mode='r', encoding='utf-8') as archivo:
            contenido = archivo.read()
            return contenido

    except FileNotFoundError:
        print(f"‚ùå Error: El archivo '{ruta_archivo}' no fue encontrado.")
        return None
    except Exception as e:
        print(f"‚ùå Error al leer el archivo: {e}")
        return None


# Limpia, analiza el texto, muestra las estad√≠sticas y genera la Nube de Palabras
def analizar_texto(texto: str):

    # 1. LIMPIEZA INICIAL: Convierte a min√∫sculas y elimina la puntuaci√≥n de los bordes, usamos .split() sin argumentos para dividir por cualquier espacio en blanco (incluyendo saltos de l√≠nea).
    palabras_divididas = texto.lower().split()

    # Lista para almacenar las palabras limpias y relevantes
    texto_final: List[str] = []

    # 2. PROCESAMIENTO, FILTRADO Y REFINAMIENTO
    for palabra in palabras_divididas:
        # Elimina la puntuaci√≥n de los bordes (ej: "palabra." -> "palabra")
        palabra_limpia = palabra.strip(string.punctuation)

        # Filtra palabras vac√≠as (que eran solo puntuaci√≥n), stopwords y palabras muy cortas (ej: letras sueltas)
        if palabra_limpia and palabra_limpia not in STOPWORDS_ESPANOL and len(palabra_limpia) > 2:
            texto_final.append(palabra_limpia)

    # 3. CONTEO DE FRECUENCIAS

    # collections.Counter es ideal para este prop√≥sito.
    contador_palabras = collections.Counter(texto_final)

    # 4. C√ÅLCULO DE ESTAD√çSTICAS
    total_palabras = len(texto_final)
    palabras_unicas = len(contador_palabras)

    # --- SALIDA DE ESTAD√çSTICAS EN CONSOLA ---
    print("\n" + "="*40)
    print("--- ‚úÖ ESTAD√çSTICAS DEL TEXTO ANALIZADO ---")
    print(f"Total de palabras (relevantes y limpias): {total_palabras}")
    print(f"Palabras √∫nicas (tama√±o del vocabulario): {palabras_unicas}")
    print("="*40)

    print("\n--- üîé TOP 10 PALABRAS M√ÅS COMUNES ---")
    if contador_palabras:
        # .most_common(10) devuelve las 10 tuplas (palabra, frecuencia) m√°s frecuentes.
        for palabra, frecuencia in contador_palabras.most_common(10):
            print(f"'{palabra}': {frecuencia} veces")
    else:
        print("No se encontraron palabras relevantes despu√©s del filtrado.")

    # --- GENERACI√ìN Y EXPORTACI√ìN DE NUBE DE PALABRAS ---
    if contador_palabras:
        # 1. Crea el objeto WordCloud con par√°metros de dise√±o.
        wc = WordCloud(
            background_color="white",
            width=800,
            height=400,
            # Asegura el uso de la lista de stopwords de Python
            stopwords=STOPWORDS_ESPANOL,
            # Evita contar frases, solo palabras individuales
            collocations=False
        )

        # 2. Genera la imagen a partir del objeto Counter (las frecuencias).
        wc.generate_from_frequencies(contador_palabras)

        nombre_archivo = "wordcloud_output.png"

        # OBTENEMOS LA RUTA ABSOLUTA DEL SCRIPT:
        # __file__ contiene la ruta del script, pero solo si se ejecuta directamente, os.path.abspath lo convierte en una ruta absoluta, os.path.dirname obtiene el directorio de esa ruta absoluta, y os.path.join une el directorio con el nombre del archivo de salida.
        try:
            # Necesario para el entorno de ejecuci√≥n, donde __file__ puede no estar definido
            script_dir = os.path.dirname(os.path.abspath(__file__))
        except NameError:
            # Fallback si __file__ no est√° disponible (ej: en algunos shells interactivos)
            script_dir = os.getcwd()

        # Construimos la ruta completa donde se guardar√° el archivo
        ruta_salida_completa = os.path.join(script_dir, nombre_archivo)

        # 3. Guarda la imagen generada como un archivo PNG.
        wc.to_file(ruta_salida_completa)
        print(
            f"\n‚ú® NUBE DE PALABRAS CREADA: Se ha guardado el archivo '{ruta_salida_completa}' en la carpeta del script.")

        # COMENTARIO CR√çTICO PARA EL PORTAFOLIO:
        print("\n--- NOTA IMPORTANTE PARA EL VISUALIZADOR ---")
        print("El comando 'plt.show()' no es compatible con el entorno web de Canvas.")
        print("Si ejecutas este archivo Python de forma local, el archivo 'wordcloud_output.png' se generar√° en tu carpeta y la siguiente l√≠nea lo mostrar√°")

        # 4. Muestra la imagen en la pantalla usando Matplotlib (descomentar y ejecutar localmente)
        # plt.imshow(wc, interpolation='bilinear')
        # plt.axis("off")
        # plt.show()

    else:
        print("‚ö†Ô∏è Advertencia: No hay suficientes palabras para generar la nube.")


# Funci√≥n principal para gestionar el men√∫ y la entrada de texto.
def main():
    # Bucle infinito para permitir m√∫ltiples an√°lisis.
    while True:
        print("\n--- ANALIZADOR DE TEXTO Y NUBE DE PALABRAS (PYTHON) ---")
        print("1. Ingresar texto directamente")
        print("2. Leer texto desde un archivo (.txt)")
        print("3. Salir")

        opcion = input("Elige una opci√≥n (1, 2, 3): ").strip()

        if opcion == '3':
            print("üëã ¬°Hasta pronto!")
            break

        texto = None
        if opcion == '1':
            # Opci√≥n 1: lee la entrada del usuario directamente.
            print("\nPega o escribe tu p√°rrafo aqu√≠ (finaliza con ENTER):")
            texto = input()

        elif opcion == '2':
            # Opci√≥n 2: pide la ruta y usa la funci√≥n de lectura segura.
            ruta = input(
                "Ingresa la ruta completa del archivo .txt (ej: archivo.txt): ").strip()
            texto = leer_archivo(ruta)

        else:
            print("‚ùå Opci√≥n no v√°lida.")
            continue

        # Solo procede al an√°lisis si la variable 'texto' tiene contenido.
        if texto and texto.strip():
            analizar_texto(texto)
        elif texto is not None:
            print("‚ùå El texto ingresado o le√≠do est√° vac√≠o. Int√©ntalo de nuevo.")


if __name__ == "__main__":
    # La variable __file__ solo est√° definida cuando el script se ejecuta directamente, esta verificaci√≥n asegura que el script_dir funcione correctamente en 'analizar_texto'.
    main()
